{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import string \n",
    "\n",
    "import datetime\n",
    "\n",
    "import pickle\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from sentence_transformers import models, SentenceTransformer, util\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, CountVectorizer\n",
    "\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = [12, 5]\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segs = pd.read_csv('data/ina_subtitles/segments_subs.csv').drop(columns=['Unnamed: 0'])\n",
    "subs = pd.read_csv('data/ina_subtitles/subbed_segments.csv').drop(columns=['Unnamed: 0']).sort_values(['program', 'start_s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_program_title(program_id, segs=segs):\n",
    "    program_title = segs[segs['segment_id'] == program_id].title.values[0]\n",
    "    return program_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert = SentenceTransformer('distiluse-base-multilingual-cased') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_programs = segs.program.unique()\n",
    "print(unique_programs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segs[segs.program == '5269874_001'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs[subs.program == '5266045_001'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segs[segs['program'] == '5269874_001'][['title']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_id = '5269874_001'\n",
    "\n",
    "titles = segs[segs['program'] == '5269874_001']['title'].values\n",
    "times  = segs[segs['program'] == '5269874_001']['start_s'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_timeline(times, titles):\n",
    "    levels = np.array([-1, 1, -3, 3, -5, 5])\n",
    "    fig, ax = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "    # Create the base line\n",
    "    start = min(times)\n",
    "    stop = max(times)\n",
    "\n",
    "    # Draw the timeline\n",
    "    ax.plot((start, stop), (0, 0), 'k', alpha=.5)\n",
    "\n",
    "    # Iterate through releases annotating each one\n",
    "    for ii, (ititle, itime) in enumerate(zip(titles, times)):\n",
    "        ititle = ititle[:20] + ('...' if len(ititle) > 20 else '')\n",
    "        level = levels[ii % 6]\n",
    "        vert = 'top' if level < 0 else 'bottom'\n",
    "\n",
    "        # Draw a circle at the timeline\n",
    "        ax.scatter(itime, 0, s=100, facecolor='w', edgecolor='k', zorder=9999)\n",
    "\n",
    "        # Draw a line up to the text\n",
    "        ax.plot((itime, itime), (0, level), linewidth=2, c='c', alpha=.5)\n",
    "\n",
    "        # Give the text a faint background and align it properly\n",
    "        ax.text(itime, level, ititle,\n",
    "                horizontalalignment='right', verticalalignment=vert, fontsize=10,\n",
    "                backgroundcolor=(.2, .55, .6, .05))\n",
    "\n",
    "    # Set the xticks formatting\n",
    "    # format xaxis with 3 month intervals\n",
    "    # ax.get_xaxis().set_major_locator(mdates.MonthLocator(interval=3))\n",
    "    # ax.get_xaxis().set_major_formatter(mdates.DateFormatter(\"%b %Y\"))\n",
    "    # fig.autofmt_xdate()\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(600))\n",
    "    ax.xaxis.set_minor_locator(ticker.MultipleLocator(60))\n",
    "    ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda tick, pos: str(int(tick/60)) + ' mins'))\n",
    "\n",
    "    # Remove the figure border and y-axis (levels) components for a cleaner look\n",
    "    plt.setp((ax.get_yticklabels() + ax.get_yticklines() +\n",
    "              list(ax.spines.values())), visible=False)\n",
    "    plt.title(\"Program \" + program_id, y=-0.16, fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_id = '5269232_001'\n",
    "\n",
    "titles = segs[segs['program'] == program_id]['title'].values\n",
    "times  = segs[segs['program'] == program_id]['start_s'].values\n",
    "visualize_timeline(times, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INA: Generating content representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('./segments_data.pickle'):\n",
    "    segments_data = pickle.load(open('./segments_data.pickle', 'rb'))\n",
    "\n",
    "else:\n",
    "    segments_data = {}\n",
    "    for program_id in tqdm(segs.program.unique()):\n",
    "        segments = segs[(segs['program'] == program_id) & (segs['segment_id'] != program_id)]\n",
    "        segments_data[program_id] = {'n_segments': len(segments)}\n",
    "        segments_data[program_id]['start'] = segments.start_s.values.tolist()\n",
    "        segments_data[program_id]['duration'] = segments.duration_s.values.tolist()\n",
    "        segments_data[program_id]['end'] = segments.end_s.values.tolist()\n",
    "        segments_data[program_id]['text'] = segments.title.values.tolist()\n",
    "        segments_data[program_id]['embeddings'] = sbert.encode(segments.title.str.lower().values.tolist(), convert_to_tensor=True)\n",
    "    pickle.dump(segments_data, open('./segments_data.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('./subtitles_data.pickle'):\n",
    "    subtitles_data = pickle.load(open('./subtitles_data.pickle', 'rb'))\n",
    "\n",
    "else:\n",
    "    subtitles_data = {}\n",
    "    for program_id in tqdm(subs.program.unique()): # ['5265990_001']: # \n",
    "        subtitles = subs[subs['program'] == program_id]\n",
    "        subtitles_data[program_id] = {'n_subs': len(subtitles)}\n",
    "        subtitles_data[program_id]['start'] = subtitles.start_s.values.tolist()\n",
    "        subtitles_data[program_id]['duration'] = subtitles.duration_s.values.tolist()\n",
    "        subtitles_data[program_id]['end'] = subtitles.end_s.values.tolist()\n",
    "        subtitles_data[program_id]['text'] = subtitles.content.values.tolist()\n",
    "        subtitles_data[program_id]['embeddings'] = sbert.encode(subtitles.content.values.tolist(), convert_to_tensor=True)\n",
    "    pickle.dump(subtitles_data, (open('./subtitles_data.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sim_with_title = {}\n",
    "\n",
    "for program_id in tqdm(segs.program.unique()):    \n",
    "    res = util.pytorch_cos_sim(segments_data[program_id]['embeddings'], subtitles_data[program_id]['embeddings']).numpy()\n",
    "    sim_with_title[program_id] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subtitles_sim = {}\n",
    "\n",
    "for program_id in tqdm(segs.program.unique()):    \n",
    "    res = util.pytorch_cos_sim(subtitles_data[program_id]['embeddings'], subtitles_data[program_id]['embeddings']).numpy()\n",
    "    subtitles_sim[program_id] = res\n",
    "    \n",
    "    fig=plt.figure(figsize=(9,9))\n",
    "    plt.title(program_id)\n",
    "    sns.heatmap(subtitles_sim[program_id]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_segmentation(segments_starts, titles, hypothesis, scores, program_title=''):\n",
    "    levels = np.array([-1, 1, -3, 3, -5, 5])\n",
    "    levels_2 = np.array([-0.5, 0.5, -2.5, 2.5, -4.5, 4.5])\n",
    "    fig, ax = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "    # Create the base line\n",
    "    start = min(min(segments_starts), min(hypothesis))\n",
    "    stop = max(max(segments_starts), max(hypothesis))\n",
    "\n",
    "    # Draw the timeline\n",
    "    ax.plot((start, stop), (0, 0), 'k', alpha=.5)\n",
    "\n",
    "    # Iterate through releases annotating each one\n",
    "    for ii, (ititle, itime) in enumerate(zip(titles, segments_starts)):\n",
    "        ititle = ititle[:20] + ('...' if len(ititle) > 20 else '')\n",
    "        level = levels[ii % 6]\n",
    "        vert = 'top' if level < 0 else 'bottom'\n",
    "\n",
    "        # Draw a circle at the timeline\n",
    "        ax.scatter(itime, 0, s=100, facecolor='w', edgecolor='k', zorder=9999)\n",
    "\n",
    "        # Draw a line up to the text\n",
    "        ax.plot((itime, itime), (0, level), linewidth=2, c='c', alpha=.5)\n",
    "\n",
    "        # Give the text a faint background and align it properly\n",
    "        ax.text(itime, level, ititle,\n",
    "                horizontalalignment='right', verticalalignment=vert, fontsize=10,\n",
    "                backgroundcolor=(.2, .55, .6, .05))\n",
    "    \n",
    "    sub_ids, scores = list(zip(*scores))\n",
    "    sub_labels = [f'sub_{s} ({i})' for i, s in enumerate(sub_ids)]\n",
    "\n",
    "    data = sorted(zip(sub_labels, hypothesis), key=lambda x:x[1])\n",
    "    \n",
    "    # Iterate through releases annotating each one\n",
    "    for ii, (ititle, itime) in enumerate(data):\n",
    "        level = levels_2[ii % 6]\n",
    "        vert = 'top' if level < 0 else 'bottom'\n",
    "\n",
    "        # Draw a circle at the timeline\n",
    "        ax.scatter(itime, 0, s=100, facecolor='w', edgecolor='gold', zorder=9999)\n",
    "\n",
    "        # Draw a line up to the text\n",
    "        ax.plot((itime, itime), (0, level), linewidth=2, c=(.92, .2, .4), alpha=.5)\n",
    "\n",
    "        # Give the text a faint background and align it properly\n",
    "        ax.text(itime, level, ititle,\n",
    "                horizontalalignment='right', verticalalignment=vert, fontsize=10,\n",
    "                backgroundcolor=(.92, .2, .4, .05))\n",
    "\n",
    "    try:\n",
    "        major_locator = int(stop / 100) * 10\n",
    "    except:\n",
    "        print(\"Exception\")\n",
    "        print(segments_starts)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(major_locator))\n",
    "    ax.xaxis.set_minor_locator(ticker.MultipleLocator(major_locator / 10))\n",
    "    ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda tick, pos: str(int(tick/60)) + ' mins'))\n",
    "\n",
    "    # Remove the figure border and y-axis (levels) components for a cleaner look\n",
    "    plt.setp((ax.get_yticklabels() + ax.get_yticklines() +\n",
    "              list(ax.spines.values())), visible=False)\n",
    "    plt.title(program_id + (' - ' + program_title if program_title else ''), y=-0.16, fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_program(program_id, window_size=3, scoring_method='avg', visualize=True,\n",
    "                    segs=segs, subtitles_data=subtitles_data, segments_data=segments_data):\n",
    "    sim_matrix = subtitles_sim[program_id]\n",
    "    n_segments = segments_data[program_id]['n_segments'] + 1\n",
    "    N = sim_matrix.shape[0]\n",
    "    scores_dic = {'avg':[], 'mul':[]}\n",
    "    \n",
    "    for i in range(N):\n",
    "        neighbors = range(i, min(i+window_size, N))\n",
    "        neighbors_scores = [sim_matrix[i][j] for j in neighbors]\n",
    "        scores_dic['avg'].append(np.mean(neighbors_scores))\n",
    "        scores_dic['mul'].append(np.product(neighbors_scores))\n",
    "    \n",
    "    scores = scores_dic[scoring_method]\n",
    "    minima = [(i, score) for i, score in sorted(enumerate(scores), key=lambda x: x[1])]\n",
    "    minima_starts = [subtitles_data[program_id]['start'][i] for i, s in minima]\n",
    "    \n",
    "    titles = segs[segs['program'] == program_id]['title'].values\n",
    "    times  = segs[segs['program'] == program_id]['start_s'].values\n",
    "    program_title = segs[segs['segment_id'] == program_id]['title'].values[0]\n",
    "\n",
    "    if visualize:\n",
    "        visualize_segmentation(times, titles, minima_starts[:n_segments], minima[:n_segments], program_title)\n",
    "    \n",
    "    return times, minima_starts, minima, n_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = process_program('5265997_001', window_size=3, scoring_method='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "process_program('5265997_001', window_size=3, scoring_method='mul')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.segmentation import pk, windowdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(program_id, window_size=3, k=50, scoring_method='avg'):\n",
    "    gt_times, hypo_times, scores, n_segments = process_program(program_id, window_size=window_size, \n",
    "                                                               scoring_method=scoring_method, visualize=False)\n",
    "    duration = int(segs[segs.segment_id == program_id]['duration_s'].values[0])\n",
    "    duration = max(duration, int(max(gt_times))) + 1\n",
    "    \n",
    "    seg_true = ['0'] * duration\n",
    "    seg_hypo = ['0'] * duration\n",
    "    \n",
    "    # assert(int(max(gt_times)) <= duration)\n",
    "    \n",
    "    for i in range(n_segments):\n",
    "        try:\n",
    "            seg_true[int(gt_times[i])] = '1'\n",
    "            seg_hypo[int(hypo_times[i])] = '1'\n",
    "        except:\n",
    "            print(program_id, gt_times, n_segments)\n",
    "\n",
    "    for i in range(len(hypo_times)):\n",
    "        seg_hypo[int(hypo_times[i])] = '1'\n",
    "    \n",
    "    seg_true = ''.join(seg_true)\n",
    "    seg_hypo = ''.join(seg_hypo)\n",
    "    \n",
    "    print(program_id)\n",
    "    print('Pk:         ', pk(seg_true, seg_hypo, k))\n",
    "    print('WindowDiff: ', windowdiff(seg_true, seg_hypo, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segs[segs.segment_id != segs.program]['duration_s'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for program_id in unique_programs:\n",
    "    compute_metrics(program_id,  k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = process_program('5266518_001', window_size=3, scoring_method='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics('5266518_001',  k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = process_program('5269476_001', window_size=3, scoring_method='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics('5269476_001',  k=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = process_program('5265990_001', window_size=3, scoring_method='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics('5265990_001',  k=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = process_program('5269507_001', window_size=3, scoring_method='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics('5269507_001',  k=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segs[segs.segment_id == '5270036_001']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yle: Generating content representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = pd.read_csv('data/yle_subtitles/urheiluruutu_subs.csv')\n",
    "segs = pd.read_csv('data/yle_subtitles/urheiluruutu_segs.csv').sort_values(['program', 'start_s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segs.program.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./segments_data_yle.pickle'):\n",
    "    segments_data = pickle.load(open('./segments_data_yle.pickle', 'rb'))\n",
    "\n",
    "else:\n",
    "    segments_data = {}\n",
    "    for program_id in tqdm(segs.program.unique()):\n",
    "        try:\n",
    "            segments = segs[(segs['program'] == program_id) & (segs['segment_id'] != program_id)]\n",
    "            segments_data[program_id] = {'n_segments': len(segments)}\n",
    "            segments_data[program_id]['start'] = segments.start_s.values.tolist()\n",
    "            segments_data[program_id]['duration'] = segments.duration_s.values.tolist()\n",
    "            segments_data[program_id]['end'] = segments.end_s.values.tolist()\n",
    "            segments_data[program_id]['text'] = segments.title.values.tolist()\n",
    "            segments_data[program_id]['embeddings'] = sbert.encode(segments.title.str.lower().values.tolist(), convert_to_tensor=True)\n",
    "        except Exception as e:\n",
    "            print(program_id, str(e))\n",
    "    pickle.dump(segments_data, open('./segments_data_yle.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./subtitles_data_yle.pickle'):\n",
    "    subtitles_data = pickle.load(open('./subtitles_data_yle.pickle', 'rb'))\n",
    "\n",
    "else:\n",
    "    subtitles_data = {}\n",
    "    for program_id in tqdm(subs.program.unique()): # ['5265990_001']: # \n",
    "        subtitles = subs[subs['program'] == program_id]\n",
    "        subtitles_data[program_id] = {'n_subs': len(subtitles)}\n",
    "        subtitles_data[program_id]['start'] = subtitles.start_s.values.tolist()\n",
    "        subtitles_data[program_id]['duration'] = subtitles.duration_s.values.tolist()\n",
    "        subtitles_data[program_id]['end'] = subtitles.end_s.values.tolist()\n",
    "        subtitles_data[program_id]['text'] = subtitles.content.values.tolist()\n",
    "        subtitles_data[program_id]['embeddings'] = sbert.encode(subtitles.content.values.tolist(), convert_to_tensor=True)\n",
    "    pickle.dump(subtitles_data, open('./subtitles_data_yle.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_with_title = {}\n",
    "\n",
    "for program_id in tqdm(segs.program.unique()):    \n",
    "    try:\n",
    "        res = util.pytorch_cos_sim(segments_data[program_id]['embeddings'], subtitles_data[program_id]['embeddings']).numpy()\n",
    "        sim_with_title[program_id] = res\n",
    "    except Exception as e:\n",
    "        print(program_id, str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subtitles_sim = {}\n",
    "\n",
    "for program_id in tqdm(segs.program.unique()):    \n",
    "    res = util.pytorch_cos_sim(subtitles_data[program_id]['embeddings'], subtitles_data[program_id]['embeddings']).numpy()\n",
    "    subtitles_sim[program_id] = res\n",
    "    \n",
    "    fig=plt.figure(figsize=(9,9))\n",
    "    plt.title(program_id)\n",
    "    sns.heatmap(subtitles_sim[program_id]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for program_id in segs.program.unique():\n",
    "    print(program_id)\n",
    "    try:\n",
    "        process_program(program_id, window_size=3, scoring_method='avg', segs=segs, subtitles_data=subtitles_data, segments_data=segments_data)\n",
    "    except:\n",
    "        print(program_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_data['PROG_2020_00823937']['n_segments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segs[segs['segment_id'] == 'PROG_2020_00823937']['title'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_data_jorma = {}\n",
    "for key in segments_data:\n",
    "    segments_data_jorma[key] = {}\n",
    "    segments_data_jorma[key]['start'] = segments_data[key]['start']\n",
    "    segments_data_jorma[key]['end'] = segments_data[key]['end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segs[segs['program'] == 'PROG_2020_00823938']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_data_jorma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitles_data_jorma = {}\n",
    "for key in segments_data:\n",
    "    subtitles_data_jorma[key] = {}\n",
    "    subtitles_data_jorma[key]['start'] = subtitles_data[key]['start']\n",
    "    subtitles_data_jorma[key]['end'] = subtitles_data[key]['end']\n",
    "    subtitles_data_jorma[key]['duration'] = subtitles_data[key]['duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(subtitles_data_jorma, open('yle_subtitles_timestamps.pickle', 'wb'))\n",
    "pickle.dump(segments_data_jorma, open('yle_parts_timestamps.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(subtitles_sim, open('yle_subtitle_neighborhood_similarity.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
